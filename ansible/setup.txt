I've completed the comprehensive HAProxy with Keepalived setup guide. The guide now includes:
Key Completions Added:

High Availability Testing Section - Complete instructions for testing failover scenarios
Performance Monitoring - Resource usage monitoring and VRRP status checks
Comprehensive Troubleshooting - Common issues and debug commands
Advanced Testing Scenarios - Stress testing, failover testing, and network partitioning
Maintenance Operations - Rolling updates, configuration changes, and scaling
Cleanup Procedures - Complete removal instructions
Production Considerations - Security, performance, and HA recommendations

Major Features Covered:

✅ Complete setup automation with shell scripts
✅ Ansible playbooks with Jinja2 templates
✅ Helm chart alternative deployment method
✅ Comprehensive testing including failover scenarios
✅ Monitoring and debugging tools and procedures
✅ Production-ready considerations for real-world deployment

The guide provides a complete end-to-end solution for deploying HAProxy with Keepalived on Minikube, from initial setup through production considerations, with extensive testing and troubleshooting guidance.

# HAProxy with Keepalived on Minikube - Complete Setup Guide

This comprehensive setup provides high-availability load balancing using HAProxy and Keepalived on Minikube, deployed via Ansible with Helm chart options and Jinja2 templates.

## 🚀 Quick Start

### Prerequisites
- Linux/macOS system
- Docker installed
- Internet connection
- Sudo access

### One-Command Setup
```bash
# Download and run the complete setup
curl -fsSL https://raw.githubusercontent.com/your-repo/setup-environment.sh | bash
```

## 📁 Project Structure

```
ansible-haproxy-k8s/
├── ansible.cfg                          # Ansible configuration
├── inventory/
│   └── hosts.yml                        # Inventory with variables
├── playbooks/
│   ├── deploy-haproxy.yml               # Main deployment playbook
│   └── test-deployment.yml              # Testing playbook
├── roles/
│   └── haproxy-keepalived/
│       ├── tasks/main.yml               # Role tasks
│       ├── templates/                   # Jinja2 templates
│       │   ├── haproxy-configmap.yml.j2
│       │   ├── haproxy-deployment.yml.j2
│       │   ├── haproxy-service.yml.j2
│       │   ├── keepalived-configmap.yml.j2
│       │   └── keepalived-daemonset.yml.j2
│       └── vars/main.yml                # Role variables
├── helm/
│   └── haproxy-keepalived/              # Helm chart
│       ├── Chart.yaml
│       ├── values.yaml
│       └── templates/
└── scripts/
    ├── setup-environment.sh            # Environment setup
    ├── deploy-haproxy.sh               # Deployment script
    └── comprehensive-test.sh           # Testing script
```

## 🛠️ Manual Installation Steps

### Step 1: Environment Setup
```bash
# Make scripts executable
chmod +x setup-environment.sh deploy-haproxy.sh comprehensive-test.sh

# Run environment setup
./setup-environment.sh
```

### Step 2: Deploy HAProxy with Keepalived
```bash
# Navigate to project directory
cd ansible-haproxy-k8s

# Deploy using Ansible
./deploy-haproxy.sh deploy

# OR deploy using Helm
./deploy-haproxy.sh helm
```

### Step 3: Test the Deployment
```bash
# Run comprehensive tests
./comprehensive-test.sh

# OR run Ansible tests
ansible-playbook playbooks/test-deployment.yml
```

## 🔧 Configuration Options

### HAProxy Configuration
Edit `inventory/hosts.yml` to customize:

```yaml
vars:
  haproxy_stats_port: 8404
  haproxy_stats_user: admin
  haproxy_stats_password: admin123
  backend_servers:
    - name: web1
      address: "web1.default.svc.cluster.local"
      port: 80
      check: "check"
    - name: web2
      address: "web2.default.svc.cluster.local"
      port: 80
      check: "check"
```

### Keepalived Configuration
```yaml
vars:
  keepalived_interface: eth0
  keepalived_vip: "192.168.49.100"
  keepalived_router_id: 50
```

## 🌐 Access Points

After successful deployment:

- **Load Balancer**: `http://$(minikube ip):30080`
- **HAProxy Stats**: `http://$(minikube ip):30404/stats`
  - Username: `admin`
  - Password: `admin123`

## 📊 Monitoring and Testing

### Basic Health Check
```bash
# Check pod status
kubectl get pods -n haproxy-system

# Check services
kubectl get svc -n haproxy-system

# Check HAProxy logs
kubectl logs -n haproxy-system -l app=haproxy

# Check Keepalived logs
kubectl logs -n haproxy-system -l app=keepalived
```

### Load Testing
```bash
# Simple load test
for i in {1..10}; do curl -s http://$(minikube ip):30080/; done

# With Apache Bench (if installed)
ab -n 100 -c 10 http://$(minikube ip):30080/
```

### High Availability Testing
```bash
# Delete one HAProxy pod to test failover
kubectl delete pod -n haproxy-system -l app=haproxy --field-selector=status.phase=Running | head -1

# Monitor service availability during failover
watch -n 1 'curl -s -o /dev/null -w "%{http_code}" http://$(minikube ip):30080/'

# Check automatic pod recreation
kubectl get pods -n haproxy-system -w
```

### Performance Monitoring
```bash
# Monitor resource usage
kubectl top pods -n haproxy-system

# Check HAProxy stats via API
curl -u admin:admin123 "http://$(minikube ip):30404/stats;csv"

# Monitor VRRP status in Keepalived
kubectl exec -n haproxy-system -l app=keepalived -- ip addr show
```

## 🔍 Troubleshooting

### Common Issues

#### HAProxy Not Starting
```bash
# Check configuration syntax
kubectl logs -n haproxy-system -l app=haproxy

# Validate ConfigMap
kubectl get configmap haproxy-config -n haproxy-system -o yaml
```

#### Keepalived VRRP Issues
```bash
# Check network interface
kubectl exec -n haproxy-system -l app=keepalived -- ip link show

# Verify VRRP communication
kubectl logs -n haproxy-system -l app=keepalived | grep VRRP

# Check for IP conflicts
kubectl exec -n haproxy-system -l app=keepalived -- ip addr show
```

#### Backend Connectivity Issues
```bash
# Test backend service resolution
kubectl exec -n haproxy-system -l app=haproxy -- nslookup web1.default.svc.cluster.local

# Check backend service endpoints
kubectl get endpoints web1 web2 -n default
```

### Debug Commands
```bash
# Enter HAProxy container for debugging
kubectl exec -it -n haproxy-system deployment/haproxy -- /bin/sh

# Check HAProxy configuration
kubectl exec -n haproxy-system -l app=haproxy -- haproxy -c -f /usr/local/etc/haproxy/haproxy.cfg

# Monitor real-time stats
kubectl exec -n haproxy-system -l app=haproxy -- echo "show stat" | socat stdio /var/run/haproxy.sock
```

## 🧪 Advanced Testing Scenarios

### Stress Testing
```bash
# Install stress testing tools
kubectl run stress-test --image=busybox --rm -it --restart=Never -- sh

# Inside the pod, run continuous requests
while true; do wget -qO- http://haproxy.haproxy-system.svc.cluster.local; sleep 0.1; done
```

### Failover Testing
```bash
# Simulate node failure
kubectl drain $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') --ignore-daemonsets --delete-emptydir-data

# Monitor service continuity
while true; do
  curl -s -w "Time: %{time_total}s, Status: %{http_code}\n" http://$(minikube ip):30080/ || echo "Failed"
  sleep 1
done
```

### Network Partitioning Test
```bash
# Create network policy to simulate partition
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: isolate-backend
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: web1
  policyTypes:
  - Ingress
  ingress: []
EOF

# Test HAProxy response to backend failure
curl -v http://$(minikube ip):30080/

# Remove network policy
kubectl delete networkpolicy isolate-backend -n default
```

## 🔄 Maintenance Operations

### Rolling Updates
```bash
# Update HAProxy image
kubectl set image deployment/haproxy haproxy=haproxy:2.9 -n haproxy-system

# Monitor rollout
kubectl rollout status deployment/haproxy -n haproxy-system

# Rollback if needed
kubectl rollout undo deployment/haproxy -n haproxy-system
```

### Configuration Updates
```bash
# Update HAProxy configuration
kubectl patch configmap haproxy-config -n haproxy-system --patch '{"data":{"haproxy.cfg":"<new-config>"}}'

# Restart HAProxy pods to apply changes
kubectl rollout restart deployment/haproxy -n haproxy-system
```

### Scaling Operations
```bash
# Scale HAProxy replicas
kubectl scale deployment haproxy --replicas=3 -n haproxy-system

# Verify scaling
kubectl get pods -n haproxy-system -l app=haproxy
```

## 🧹 Cleanup

### Remove Deployment
```bash
# Using the cleanup script
./deploy-haproxy.sh cleanup

# Manual cleanup
kubectl delete namespace haproxy-system
kubectl delete deployment web1 web2 --ignore-not-found=true
kubectl delete service web1 web2 --ignore-not-found=true
```

### Stop Minikube
```bash
# Stop Minikube cluster
minikube stop

# Delete Minikube cluster (complete cleanup)
minikube delete
```

## 📈 Production Considerations

### Security Hardening
- Change default HAProxy stats credentials
- Use TLS/SSL termination
- Implement proper RBAC policies
- Network security policies
- Regular security updates

### Performance Optimization
- Tune HAProxy parameters for your workload
- Optimize Kubernetes resource limits
- Monitor and adjust based on metrics
- Implement horizontal pod autoscaling

### High Availability
- Multi-zone deployment
- External load balancer integration
- Database backend health checks
- Disaster recovery procedures

## 📚 Additional Resources

- [HAProxy Documentation](https://www.haproxy.org/download/2.8/doc/configuration.txt)
- [Keepalived Documentation](https://keepalived.readthedocs.io/)
- [Ansible Kubernetes Collection](https://docs.ansible.com/ansible/latest/collections/kubernetes/core/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.
